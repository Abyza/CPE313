{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "annual-sandwich",
      "metadata": {
        "id": "annual-sandwich"
      },
      "source": [
        "# Hands-on Activity 3.2 - Transfer Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Technological Institute of the Philippines | Quezon City - Computer Engineering\n",
        "--- | ---\n",
        "Course Code: | CPE 313\n",
        "Code Title: | Advanced Machine Learning and Deep Learning\n",
        "2nd Semester | AY 2023-2024\n",
        "<hr> | <hr>\n",
        "<u>**ACTIVITY NO.** | **Hands-on Activity 3.2 Transfer Learning**\n",
        "**Name** | Mendoza, Paulo\n",
        "<hr> | <hr>\n",
        "**Section** | CPE32S8\n",
        "**Date Performed**: | March 5, 2024\n",
        "**Date Submitted**: | March 5, 2024\n",
        "**Instructor**: | Engr. Roman M. Richard\n",
        "\n",
        "<hr>"
      ],
      "metadata": {
        "id": "nE66AR-xk9Bj"
      },
      "id": "nE66AR-xk9Bj"
    },
    {
      "cell_type": "markdown",
      "id": "great-fireplace",
      "metadata": {
        "id": "great-fireplace"
      },
      "source": [
        "#### Objective(s):\n",
        "\n",
        "This activity aims to introduce how to apply transfer learning"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "subjective-elimination",
      "metadata": {
        "id": "subjective-elimination"
      },
      "source": [
        "#### Intended Learning Outcomes (ILOs):\n",
        "* Demonstrate how to build and train neural network\n",
        "* Demonstrate how to apply transfer learning in neural network\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "simplified-azerbaijan",
      "metadata": {
        "id": "simplified-azerbaijan"
      },
      "source": [
        "#### Resources:\n",
        "* Jupyter Notebook\n",
        "* CIFAR-10 dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ordinary-crime",
      "metadata": {
        "id": "ordinary-crime"
      },
      "source": [
        "#### Procedures\n",
        "Load the necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "comic-joining",
      "metadata": {
        "id": "comic-joining"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import datetime\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import backend as K"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "moral-chair",
      "metadata": {
        "id": "moral-chair"
      },
      "source": [
        "Set the parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sticky-metallic",
      "metadata": {
        "id": "sticky-metallic"
      },
      "outputs": [],
      "source": [
        "now = datetime.datetime.now\n",
        "batch_size = 128\n",
        "num_classes = 5\n",
        "epochs = 5\n",
        "img_rows, img_cols = 28, 28\n",
        "filters = 32\n",
        "pool_size = 2\n",
        "kernel_size = 3"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "resident-activity",
      "metadata": {
        "id": "resident-activity"
      },
      "source": [
        "Set how the input data is loaded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "measured-queens",
      "metadata": {
        "id": "measured-queens"
      },
      "outputs": [],
      "source": [
        "\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    input_shape = (img_rows, img_cols, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "jewish-russell",
      "metadata": {
        "id": "jewish-russell"
      },
      "source": [
        "* Write a function to include all the training steps.\n",
        "* Use the model, training set, test set and number of classes as function parameters\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "julian-batch",
      "metadata": {
        "id": "julian-batch"
      },
      "outputs": [],
      "source": [
        "def train_model(model, train, test, num_classes):\n",
        "    x_train = train[0].reshape((train[0].shape[0],) + input_shape)\n",
        "    x_test = test[0].reshape((test[0].shape[0],) + input_shape)\n",
        "    x_train = x_train.astype('float32')\n",
        "    x_test = x_test.astype('float32')\n",
        "    x_train /= 255\n",
        "    x_test /= 255\n",
        "    print('x_train shape:', x_train.shape)\n",
        "    print(x_train.shape[0], 'train samples')\n",
        "    print(x_test.shape[0], 'test samples')\n",
        "\n",
        "    # convert class vectors to binary class matrices\n",
        "    y_train = keras.utils.to_categorical(train[1], num_classes)\n",
        "    y_test = keras.utils.to_categorical(test[1], num_classes)\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adadelta',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    t = now()\n",
        "    model.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              verbose=1,\n",
        "              validation_data=(x_test, y_test))\n",
        "    print('Training time: %s' % (now() - t))\n",
        "\n",
        "    score = model.evaluate(x_test, y_test, verbose=0)\n",
        "    print('Test score:', score[0])\n",
        "    print('Test accuracy:', score[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "monetary-final",
      "metadata": {
        "id": "monetary-final"
      },
      "source": [
        "Shuffle and split the data between train and test sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hollywood-amendment",
      "metadata": {
        "id": "hollywood-amendment"
      },
      "outputs": [],
      "source": [
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "committed-bench",
      "metadata": {
        "id": "committed-bench"
      },
      "source": [
        "Create two datasets\n",
        "* one with digits below 5\n",
        "* one with 5 and above"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lesser-bradley",
      "metadata": {
        "id": "lesser-bradley"
      },
      "outputs": [],
      "source": [
        "x_train_lt5 = x_train[y_train < 5]\n",
        "y_train_lt5 = y_train[y_train < 5]\n",
        "x_test_lt5 = x_test[y_test < 5]\n",
        "y_test_lt5 = y_test[y_test < 5]\n",
        "\n",
        "x_train_gte5 = x_train[y_train >= 5]\n",
        "y_train_gte5 = y_train[y_train >= 5] - 5\n",
        "x_test_gte5 = x_test[y_test >= 5]\n",
        "y_test_gte5 = y_test[y_test >= 5] - 5"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "talented-scheme",
      "metadata": {
        "id": "talented-scheme"
      },
      "source": [
        "* Define the feature layers that will used for transfer learning\n",
        "* Freeze these layers during fine-tuning process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ranging-neutral",
      "metadata": {
        "id": "ranging-neutral"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "feature_layers = [\n",
        "    Conv2D(filters, kernel_size,\n",
        "           padding='valid',\n",
        "           input_shape=input_shape),\n",
        "    Activation('relu'),\n",
        "    Conv2D(filters, kernel_size),\n",
        "    Activation('relu'),\n",
        "    MaxPooling2D(pool_size=pool_size),\n",
        "    Dropout(0.25),\n",
        "    Flatten(),\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bulgarian-accuracy",
      "metadata": {
        "id": "bulgarian-accuracy"
      },
      "source": [
        "Define the classification layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "religious-timer",
      "metadata": {
        "id": "religious-timer"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "classification_layers = [\n",
        "    Dense(128),\n",
        "    Activation('relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(num_classes),\n",
        "    Activation('softmax')\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "yellow-puzzle",
      "metadata": {
        "id": "yellow-puzzle"
      },
      "source": [
        "Create a model by combining the feature layers and classification layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "governmental-portable",
      "metadata": {
        "id": "governmental-portable"
      },
      "outputs": [],
      "source": [
        "\n",
        "model = Sequential(feature_layers + classification_layers)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "noticed-dairy",
      "metadata": {
        "id": "noticed-dairy"
      },
      "source": [
        "Check the model summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "correct-syria",
      "metadata": {
        "id": "correct-syria",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7398c234-67d1-4af1-f46a-163707883057"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
            "                                                                 \n",
            " activation (Activation)     (None, 26, 26, 32)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 24, 24, 32)        9248      \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 24, 24, 32)        0         \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 12, 12, 32)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 12, 12, 32)        0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 4608)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               589952    \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 128)               0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 5)                 645       \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 5)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 600165 (2.29 MB)\n",
            "Trainable params: 600165 (2.29 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "productive-regular",
      "metadata": {
        "id": "productive-regular"
      },
      "source": [
        " Train the  model on the digits 5,6,7,8,9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "distinct-ticket",
      "metadata": {
        "id": "distinct-ticket",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fac3700-b5fd-449c-c926-d8f6a48c7342"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (29404, 28, 28, 1)\n",
            "29404 train samples\n",
            "4861 test samples\n",
            "Epoch 1/5\n",
            "230/230 [==============================] - 51s 219ms/step - loss: 1.6022 - accuracy: 0.2107 - val_loss: 1.5792 - val_accuracy: 0.2917\n",
            "Epoch 2/5\n",
            "230/230 [==============================] - 52s 228ms/step - loss: 1.5770 - accuracy: 0.2673 - val_loss: 1.5523 - val_accuracy: 0.4470\n",
            "Epoch 3/5\n",
            "230/230 [==============================] - 51s 221ms/step - loss: 1.5522 - accuracy: 0.3302 - val_loss: 1.5236 - val_accuracy: 0.5567\n",
            "Epoch 4/5\n",
            "230/230 [==============================] - 51s 222ms/step - loss: 1.5234 - accuracy: 0.3950 - val_loss: 1.4916 - val_accuracy: 0.6192\n",
            "Epoch 5/5\n",
            "230/230 [==============================] - 50s 219ms/step - loss: 1.4934 - accuracy: 0.4493 - val_loss: 1.4553 - val_accuracy: 0.6665\n",
            "Training time: 0:04:23.098578\n",
            "Test score: 1.455298662185669\n",
            "Test accuracy: 0.6665295362472534\n"
          ]
        }
      ],
      "source": [
        "train_model(model,\n",
        "            (x_train_gte5, y_train_gte5),\n",
        "            (x_test_gte5, y_test_gte5), num_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "racial-emission",
      "metadata": {
        "id": "racial-emission"
      },
      "source": [
        "Freeze only the feature layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "violent-territory",
      "metadata": {
        "id": "violent-territory"
      },
      "outputs": [],
      "source": [
        "\n",
        "for l in feature_layers:\n",
        "    l.trainable = False"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "continuous-injection",
      "metadata": {
        "id": "continuous-injection"
      },
      "source": [
        "Check again the summary and observe the parameters from the previous model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sunset-manhattan",
      "metadata": {
        "id": "sunset-manhattan",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3430406a-94f9-4832-cf3a-01a3297801bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
            "                                                                 \n",
            " activation (Activation)     (None, 26, 26, 32)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 24, 24, 32)        9248      \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 24, 24, 32)        0         \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 12, 12, 32)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 12, 12, 32)        0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 4608)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               589952    \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 128)               0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 5)                 645       \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 5)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 600165 (2.29 MB)\n",
            "Trainable params: 590597 (2.25 MB)\n",
            "Non-trainable params: 9568 (37.38 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()\n",
        "# the Non-trainable params is now 9568 not 0 anymore because we freezed the feature layers. This only means that they are all same format of numbers so it doesn't matter too much how we preprocess them."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "modern-carnival",
      "metadata": {
        "id": "modern-carnival"
      },
      "source": [
        "Train again the model using the 0 to 4 digits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "comprehensive-nurse",
      "metadata": {
        "id": "comprehensive-nurse",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34b5cae2-27c1-42e8-dbba-dffdebdbd32f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (30596, 28, 28, 1)\n",
            "30596 train samples\n",
            "5139 test samples\n",
            "Epoch 1/5\n",
            "240/240 [==============================] - 20s 79ms/step - loss: 1.5753 - accuracy: 0.3254 - val_loss: 1.5446 - val_accuracy: 0.4974\n",
            "Epoch 2/5\n",
            "240/240 [==============================] - 19s 79ms/step - loss: 1.5338 - accuracy: 0.3966 - val_loss: 1.5019 - val_accuracy: 0.5770\n",
            "Epoch 3/5\n",
            "240/240 [==============================] - 18s 76ms/step - loss: 1.4934 - accuracy: 0.4614 - val_loss: 1.4593 - val_accuracy: 0.6385\n",
            "Epoch 4/5\n",
            "240/240 [==============================] - 19s 78ms/step - loss: 1.4561 - accuracy: 0.5137 - val_loss: 1.4180 - val_accuracy: 0.6795\n",
            "Epoch 5/5\n",
            "240/240 [==============================] - 20s 82ms/step - loss: 1.4172 - accuracy: 0.5652 - val_loss: 1.3767 - val_accuracy: 0.7169\n",
            "Training time: 0:02:23.083420\n",
            "Test score: 1.3767049312591553\n",
            "Test accuracy: 0.7168709635734558\n"
          ]
        }
      ],
      "source": [
        "train_model(model,\n",
        "            (x_train_lt5, y_train_lt5),\n",
        "            (x_test_lt5, y_test_lt5), num_classes)\n",
        "# We got an accuracy of 71% on 5 - 9 it was 66% meaning we proved that freezing the feature layers does not have detrimental impact and it still works with 0 - 4 data.\n",
        "# Also the accuracy is higher because it already started the training on where the 1st model left of it continued learning\n",
        "# still we only use 5 epoch the accuracy was still very low on the 1st 5 epoch but if we run train_model again and again it will continue to improve I have confirmed this by running this block of code again and again\n",
        "# but don't do it too much as there can be over fitting\n",
        "# also the training time went from 4 minutes to 2 minutes this is because it only trained the classification layer not the feature layer anymore"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "numerical-integer",
      "metadata": {
        "id": "numerical-integer"
      },
      "source": [
        "#### Supplementary Activity\n",
        "Now write code to reverse this training process. That is, you will train on the digits 0-4, and then finetune only the last layers on the digits 5-9."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# i re created the features layers so that i can train the classification layer using the 0 - 4 data, because if i don't recreate this it is still frozen\n",
        "feature_layers = [\n",
        "    Conv2D(filters, kernel_size,\n",
        "           padding='valid',\n",
        "           input_shape=input_shape),\n",
        "    Activation('relu'),\n",
        "    Conv2D(filters, kernel_size),\n",
        "    Activation('relu'),\n",
        "    MaxPooling2D(pool_size=pool_size),\n",
        "    Dropout(0.25),\n",
        "    Flatten(),\n",
        "]"
      ],
      "metadata": {
        "id": "zVRrV45Njjic"
      },
      "id": "zVRrV45Njjic",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "registered-venice",
      "metadata": {
        "id": "registered-venice"
      },
      "outputs": [],
      "source": [
        "# new model from scratch but same feature and classification layer as in the procedure\n",
        "model_2 = Sequential(feature_layers + classification_layers)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# this is now the summary notice that the feature_layers not frozen so Non-trainable params is 0\n",
        "model_2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pTOZeQTfVyhc",
        "outputId": "052f409b-dd67-4ea3-adff-e07b104def6b"
      },
      "id": "pTOZeQTfVyhc",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_6 (Conv2D)           (None, 26, 26, 32)        320       \n",
            "                                                                 \n",
            " activation_8 (Activation)   (None, 26, 26, 32)        0         \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 24, 24, 32)        9248      \n",
            "                                                                 \n",
            " activation_9 (Activation)   (None, 24, 24, 32)        0         \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPoolin  (None, 12, 12, 32)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 12, 12, 32)        0         \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 4608)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               589952    \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 128)               0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 5)                 645       \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 5)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 600165 (2.29 MB)\n",
            "Trainable params: 600165 (2.29 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# here we just used values 0 - 4 first\n",
        "train_model(model_2,\n",
        "            (x_train_lt5, y_train_lt5),\n",
        "            (x_test_lt5, y_test_lt5), num_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ye4ViC2eV0Ur",
        "outputId": "8d413230-3f96-4b66-ba36-8372e053bc9a"
      },
      "id": "Ye4ViC2eV0Ur",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (30596, 28, 28, 1)\n",
            "30596 train samples\n",
            "5139 test samples\n",
            "Epoch 1/5\n",
            "240/240 [==============================] - 60s 247ms/step - loss: 1.4753 - accuracy: 0.5176 - val_loss: 1.4309 - val_accuracy: 0.7202\n",
            "Epoch 2/5\n",
            "240/240 [==============================] - 62s 258ms/step - loss: 1.4201 - accuracy: 0.5882 - val_loss: 1.3677 - val_accuracy: 0.7651\n",
            "Epoch 3/5\n",
            "240/240 [==============================] - 59s 244ms/step - loss: 1.3594 - accuracy: 0.6488 - val_loss: 1.2957 - val_accuracy: 0.7992\n",
            "Epoch 4/5\n",
            "240/240 [==============================] - 61s 253ms/step - loss: 1.2869 - accuracy: 0.6992 - val_loss: 1.2148 - val_accuracy: 0.8328\n",
            "Epoch 5/5\n",
            "240/240 [==============================] - 56s 233ms/step - loss: 1.2093 - accuracy: 0.7395 - val_loss: 1.1251 - val_accuracy: 0.8679\n",
            "Training time: 0:05:23.406826\n",
            "Test score: 1.1250667572021484\n",
            "Test accuracy: 0.8678731322288513\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Freeze only the feature_layers\n",
        "for l in feature_layers:\n",
        "    l.trainable = False"
      ],
      "metadata": {
        "id": "g8HobS_VV3Hk"
      },
      "id": "g8HobS_VV3Hk",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# now using the 5 - 9 data while using the 0 - 4 weights on feature layers\n",
        "train_model(model_2,\n",
        "            (x_train_gte5,y_train_gte5),\n",
        "            (x_test_gte5, y_test_gte5), num_classes)\n",
        "\n",
        "# again it look shorter to train because we skipped the feature layers\n",
        "# but this time the accuracy of the 1st model was higher than this 2nd iteration but is it normal since this is a case to case scenario"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ouX2xpc4V4hg",
        "outputId": "d9f2178b-6a58-4fbb-a5e2-8349f9d7fce9"
      },
      "id": "ouX2xpc4V4hg",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (29404, 28, 28, 1)\n",
            "29404 train samples\n",
            "4861 test samples\n",
            "Epoch 1/5\n",
            "230/230 [==============================] - 19s 77ms/step - loss: 1.4323 - accuracy: 0.4456 - val_loss: 1.3772 - val_accuracy: 0.5663\n",
            "Epoch 2/5\n",
            "230/230 [==============================] - 18s 78ms/step - loss: 1.3870 - accuracy: 0.4956 - val_loss: 1.3325 - val_accuracy: 0.6316\n",
            "Epoch 3/5\n",
            "230/230 [==============================] - 19s 83ms/step - loss: 1.3449 - accuracy: 0.5388 - val_loss: 1.2903 - val_accuracy: 0.6783\n",
            "Epoch 4/5\n",
            "230/230 [==============================] - 17s 74ms/step - loss: 1.3057 - accuracy: 0.5770 - val_loss: 1.2506 - val_accuracy: 0.7151\n",
            "Epoch 5/5\n",
            "230/230 [==============================] - 18s 78ms/step - loss: 1.2710 - accuracy: 0.6073 - val_loss: 1.2128 - val_accuracy: 0.7412\n",
            "Training time: 0:02:23.203627\n",
            "Test score: 1.2127958536148071\n",
            "Test accuracy: 0.7412055134773254\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cardiovascular-sapphire",
      "metadata": {
        "id": "cardiovascular-sapphire"
      },
      "source": [
        "#### Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "conditional-prerequisite",
      "metadata": {
        "id": "conditional-prerequisite"
      },
      "source": [
        "Transfer Learning is very useful. It can help save time because your machine will only have to train the classification layers. This works because they are the same data structure in a sense that it won't matter how preproccessing is done. Only needing to train the classification layers not the features layers."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Google Collab Link:"
      ],
      "metadata": {
        "id": "zIKWgrxul8tL"
      },
      "id": "zIKWgrxul8tL"
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://colab.research.google.com/drive/1ssv6zD8H3k0N4ffVETfpn6IQkR5GEWFj?usp=sharing"
      ],
      "metadata": {
        "id": "5BHgGYvHl8yi"
      },
      "id": "5BHgGYvHl8yi"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
